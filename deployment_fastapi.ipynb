{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **COVID-19 Vaccine Safety QA API**\n",
        "\n",
        "This notebook sets up an **end-to-end FastAPI service** for serving a fine-tuned LLM using a LoRA adapter.  "
      ],
      "metadata": {
        "id": "gHxX-b_hZTIQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install dependencies"
      ],
      "metadata": {
        "id": "gNdsTk6tZdt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q fastapi uvicorn pyngrok transformers peft accelerate nest_asyncio\n"
      ],
      "metadata": {
        "id": "MmV7AZrsZcMQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apply Nest AsyncIO\n",
        "Needed to run FastAPI and ngrok inside the notebook without event loop conflicts\n"
      ],
      "metadata": {
        "id": "LFEu9cZjZne1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "M500V8tYZmeR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Required Libraries"
      ],
      "metadata": {
        "id": "4r78T8kfZxpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI, Header, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "import torch\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "import threading\n",
        "import asyncio\n",
        "import time\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gRg4rvcZ0Mk",
        "outputId": "28b0cf83-75be-4abd-edef-ca57682c681a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ngrok Authentication\n",
        "Set your ngrok auth token to create a public URL\n"
      ],
      "metadata": {
        "id": "W4VGAKlfZ4oa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from pyngrok import ngrok\n",
        "ngrok_token = userdata.get('ngrok')\n",
        "ngrok.set_auth_token(ngrok_token)"
      ],
      "metadata": {
        "id": "fKdBtJwxZ8HQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize FastAPI App"
      ],
      "metadata": {
        "id": "g1RAd8s2aW3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "app = FastAPI(title=\"COVID-19 Vaccine Safety QA API\")\n"
      ],
      "metadata": {
        "id": "QarbnGROaieX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Base Model + LoRA Adapter\n"
      ],
      "metadata": {
        "id": "IgkhO5QkapMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9s_goypbMg4",
        "outputId": "d9eda5c2-e367-4d4f-cb1c-5ae365dda758"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_MODEL = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
        "LORA_PATH = \"/content/drive/MyDrive/COVID-19 Vaccine Side Effects and Safety/models\"\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load tokenizer and base model\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    BASE_MODEL,\n",
        "    torch_dtype=torch.float16 if device==\"cuda\" else torch.float32\n",
        ")\n",
        "\n",
        "# Load LoRA adapter\n",
        "model = PeftModel.from_pretrained(base_model, LORA_PATH)\n",
        "model.to(device)\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rOmClBhauGW",
        "outputId": "70691d73-92da-4f30-b5e6-a86cbf3306b2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Request & Response Schemas\n"
      ],
      "metadata": {
        "id": "4j6RBkPDa0It"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QARequest(BaseModel):\n",
        "    question: str\n",
        "\n",
        "class QAResponse(BaseModel):\n",
        "    answer: str\n"
      ],
      "metadata": {
        "id": "7g5seol9a2ra"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating End points\n"
      ],
      "metadata": {
        "id": "hq9Vgcyra5Sa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@app.get(\"/\")\n",
        "def root():\n",
        "    return {\"message\": \"API is running\"}\n",
        "\n",
        "@app.post(\"/qa/\", response_model=QAResponse)\n",
        "def get_answer(request: QARequest):\n",
        "    prompt = f\"Answer the following question concisely in plain text. Do not repeat the question.\\nQuestion: {request.question}\\nAnswer:\"\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        prompt,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=512\n",
        "    )\n",
        "    input_ids = inputs.input_ids.to(device)\n",
        "    attention_mask = inputs.attention_mask.to(device)\n",
        "\n",
        "    output_ids = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        max_new_tokens=200\n",
        "    )\n",
        "\n",
        "    full_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "    if \"Answer:\" in full_text:\n",
        "        answer = full_text.split(\"Answer:\")[-1].strip()\n",
        "    else:\n",
        "        answer = full_text.strip()\n",
        "\n",
        "    return QAResponse(answer=answer)\n"
      ],
      "metadata": {
        "id": "oAw8BIcIbG6a"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Public URL with ngrok"
      ],
      "metadata": {
        "id": "5-1d0psNbmJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "public_url = ngrok.connect(8000)\n",
        "print(\"Public URL:\", public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etW5CE1RbvE6",
        "outputId": "e7fc4ca7-296a-473d-9e41-9ce210601b27"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://nondisciplinable-subterrestrial-chante.ngrok-free.dev\" -> \"http://localhost:8000\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run FastAPI Server in Background Thread"
      ],
      "metadata": {
        "id": "jE5APxz2bx3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_fastapi_server():\n",
        "    config = uvicorn.Config(app, host=\"0.0.0.0\", port=8000, log_level=\"info\")\n",
        "    server = uvicorn.Server(config)\n",
        "    asyncio.run(server.serve())\n",
        "\n",
        "threading.Thread(target=run_fastapi_server, daemon=True).start()\n"
      ],
      "metadata": {
        "id": "WDzA5Aorb2M1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test QA Endpoint with cURL\n",
        "Send a POST request to the FastAPI `/qa/` endpoint and display only the modelâ€™s answer\n"
      ],
      "metadata": {
        "id": "F3Rv1mYjcSGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -X POST \"https://nondisciplinable-subterrestrial-chante.ngrok-free.dev/qa/\" \\\n",
        "-H \"Content-Type: application/json\" \\\n",
        "-d '{\"question\": \"What are the common side effects of COVID-19 vaccines?\"}'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CB-vpvKacxut",
        "outputId": "8070fc02-938d-4947-9d2e-9bd08145ee7d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     34.73.220.170:0 - \"POST /qa/ HTTP/1.1\" 200 OK\n",
            "{\"answer\":\"Common side effects include fever, fatigue, headache, muscle pain, joint pain, and chills. These symptoms usually last for a few days after vaccination.\"}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bcXXWtBQje5o"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}